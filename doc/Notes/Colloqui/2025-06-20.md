
# Aspetti da Sottoporre/Chiedere

> [!TODO] Calibrazione modelli di cls
> Mentre per modelli di detection e segmentazione ho il dataset coco128, per modelli di cls non ho ancora trovato un dataset. Di base è addestrato su ImageNet, quindi servirebbe un sottoinsieme di quel dataset da usare in fase di calibrazione per la quantizzazione.

> [!TODO] Quantizzazione e Performance
> Per la quantizzazione, questa sembra avere effetto benefico quando viene usato OpenVINO come provider, ma allo stesso tempo OpenVino peggiora le prestazioni per livelli normali.

> [!TODO] Gestione della Memoria nel Problema
> La memoria non sembra essere ben gestita nel problema: non so se sono io che ho definito un valore costante che lo blocca o se il problema è un altro

> [!TODO] Gestione di Più Modelli
> Il problema è stato definito per gestire più modelli, ma forse per evitare una complicazione eccessiva del problema, vista l'aggiunta della quantizzazione, si può rimanere su un modello unico.

> [!TODO] Verifica del Modello
> Quanto il risultato del modello di ottimizzazione deve essere calzante con i risultati sperimentali ottenuti (ad esempio per la latenza).



# Analisi varie fasi di Deployment

Di base abbiamo due dimensioni principali:
- Tipo di modello (Seg, Cls, Det)
- Dimensione del modello (n, s, l, x)

Ogni fase di deployment ha il suo sottospazio da analizzare.

ESPERIMENTI BASE CON LE VARIE COMBINAZIONI E POI FOCUS SU UN SOTTOINSIEME. AD ESEMPIO I DUE ESTREMI SMALL E XL.


> [!TODO] Vedere il numero di nodi
> Confronto numero di nodi tra i vari modelli per vedere quali considerare


## Profiling del Modello
Il profiling del modello varia con:
- Numero di livelli da quantizzare
	- Da cui deriva la dimensione del dataset di training e test per il regressore
- Dimensione DS calibrazione
- Dimensione DS test per il noise

Qui si potrebbe considerare un range tra i 10 e i 20 livelli da quantizzare:
- Per 10 livelli abbiamo 1024 combinazioni (500 train + 100 test). 
- Per 15 livelli abbiamo circa 32000 combinazioni
- Per 20 livelli abbiamo circa TROPPE combinazioni
Teniamo comunque conto del fatto che stiamo addestrando un regressore, quindi alla fine avere pochi punti non è proprio troppo troppo un problema (serve a quello alla fine).

Per la calibrazione abbiamo coco128 (per seg/det), quindi si può fare uno split 100 + 20.

Quantizzazione max 10 livelli (eventualmente controllare 15 livelli); dimensione del dataset fare prove e vedere dove funziona discretamente bene.

## Profiling del Server
Il profiling del server varia con:
- --cpus di Docker, quindi il limite al tempo di CPU dato al container
- Hardware sottostante; posso avere:
	- CPU
	- GPU
	- OpenVINO support
- QUESTIONE DI OPENVINO VS CPU PROVIDER

Potremmo considerare:
- 0.5 cpus per device
- 1 cpu per edge / no limit 
- no limit

Come architettura potremmo o prenderla omogenea su tutti con supporto OpenVINO, oppure metterle diverse con CPU e OpenVINO + GPU, ma bisogna fare attenzione alle bande per avere degli splitting ed evitare che venga fatto subito offloading del carico di lavoro (soprattutto se assumiamo di avere un dispositivo con GPU).

1. Tutto su device
2. Tutto su cloud (con GPU)
3. Progression
	1. edge
	2. edge + cloud

## Generazione Piano
La generazione del piano varia con:
- Stato dei server (i loro profili --> --cpus)
- Numero di server (numero di nodi di rete)
- Banda tra server
- Latenza tra server
- Memoria dei server
- Consumo energetico dei server
- Pesi
	- Latenza + Energia
- Max Energy Device
- Eventualmente anche il numero di modelli
	- Se vogliamo esplorare anche questo aspetto, oppure lasciarlo lì
- Rumore di quantizzazione accettato

Fissati gli stati dei server, direi che abbiamo:
- Numero di server --> Max 3 (device, edge, cloud/fog)
- Banda
	- Qui si dovrebbero assumere i tipi di collegamento?
		- Device con LTE
		- Edge con Wi-Fi
		- Cloud con Ethernet
- Latenza tra Server
	- Bella domanda...
- Consumi energetici
	- In base all'hardware che stiamo considerando sui dispositivi posso cercare
		- Consumi sul calcolo
		- Consumi sulla trasmissione
			- Parzialmente già trovati in [[Note Sugli Articoli#Modellazione del consumo energetico di trasmissione]]
		- Consumi su loopback
			- Questi andrebbero cercati
- Pesi
	- Qui si può fare l'analisi sui 5 casi
		- Sbilanciato in entrambi i sensi
		- Bilanciato
		- 0.75 / 0.25 e 0.25 / 0.75
- Max Energy Device
	- Qua abbiamo una diminuzione progressiva
		- Possiamo partire dal massimo (modello tutto su device) e poi diminuire di un certo step di volta in volta
- Rumore di quantizzazione
	- Partiamo da 0 e lo aumentiamo fino ad un massimo (tipo 10) che induce la quantizzazione su tutti i livelli



BANDA:
- Assumi 4G/5G device-edge (vedi tabella)
- Assumi eth edge-cloud (100 circa)

LATENZA:
- 5 ms : device-->edge
- 50 ms : edge --> cloud
- 55 ms : device --> cloud
Scenario best-station

CONSUMO ENERGETICO:
- Trasmissione --> tabellina
- Calcolo
	- Vedere consumi nominali in base ad architetture
- Trasmissione a se stesso
	- 0

Pesi:
- Estremi
- Metà
- e poi muoviti un attimo

Rumore di quantizzazione:
- Parti 0
- Sali piano piano



## Deployment del Piano
Abbastanza tranquilla come cosa: dipende per lo più dal piano che è stato generato; al più si possono valutare i tempi di messa in atto del piano.

## Uso del Piano
Questo è facile: partendo dal client facciamo x run con il piano generato.